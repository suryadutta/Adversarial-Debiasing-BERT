{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from itertools import groupby\n",
    "import copy\n",
    "import flair \n",
    "import json\n",
    "\n",
    "train_data_path=\"../data/raw/CoNLL-2003/eng.train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = [line.rstrip() for line in open(train_data_path)][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [list(g) for k,g in groupby(alist, key=lambda x: x != '') if k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[word.split() for word in sent] for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_data = []\n",
    "\n",
    "for sent in data:\n",
    "    for word in sent:\n",
    "        if word[-1]=='I-PER':\n",
    "            named_data.append(sent)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word:\n",
    "    def __init__(self, wordArray):\n",
    "        self.txt = wordArray[0]\n",
    "        self.origTxt = wordArray[0]\n",
    "        self.pos = wordArray[1]\n",
    "        self.chunk_tag = wordArray[2]\n",
    "        self.named_entity_tag = wordArray[3]\n",
    "        \n",
    "    def isPerson(self):\n",
    "        return self.named_entity_tag=='I-PER'\n",
    "\n",
    "class Sentence:\n",
    "    def __init__(self, sentArray):\n",
    "        self.words = []\n",
    "        for index, wordArray in enumerate(sentArray):   \n",
    "            new_word = Word(wordArray)\n",
    "            if (new_word.isPerson()):\n",
    "                if(len(self.words)==0 or not self.words[-1].isPerson()):\n",
    "                    self.words.append(new_word)\n",
    "            else:\n",
    "                 self.words.append(new_word)\n",
    "            \n",
    "    def getText(self):\n",
    "        \n",
    "        return_str = \"\"\n",
    "        \n",
    "        for index, word in enumerate(self.words):\n",
    "            if word.pos in ['POS','\"','.',','] or index==0:\n",
    "                return_str += word.txt\n",
    "            else:\n",
    "                return_str += ' ' + word.txt\n",
    "                \n",
    "        return return_str\n",
    "    \n",
    "    def getNameIndices(self):\n",
    "        return [index for index, word in enumerate(self.words) if word.isPerson()]\n",
    "    \n",
    "    def mask(self, index, maskName):\n",
    "        self.words[index].txt = maskName\n",
    "        \n",
    "    def getMaskedInfo(self, maskName):\n",
    "        return [(word.origTxt, index) for index,word in enumerate(self.words) if word.txt==maskName]\n",
    "    \n",
    "    def setSentiment(self, label):\n",
    "        self.sentiment = label[0].to_dict()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_sentence_generator = (Sentence(sentArray) for sentArray in named_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_sents = []\n",
    "\n",
    "for sentence in named_sentence_generator:\n",
    "    nameIndices = sentence.getNameIndices()\n",
    "    for index in nameIndices:\n",
    "        sent_copy = copy.deepcopy(sentence)\n",
    "        sent_copy.mask(index, \"[NAME]\")\n",
    "        if not sent_copy.getText()=='[NAME]':\n",
    "            masked_sents.append(sent_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_sentiment = flair.models.TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_sentences = [flair.data.Sentence(sent.getText()) for sent in masked_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_sentiment.predict(flair_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [sent.labels for sent in flair_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ for]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.Series([sent.sentiment[\"value\"] for sent in masked_sents]).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"value\": [sent.sentiment[\"value\"] for sent in masked_sents], \n",
    "                   \"confidence\": [sent.sentiment[\"confidence\"] for sent in masked_sents]})\n",
    "\n",
    "df[\"value\"] = df[\"value\"].astype(\"category\").cat.codes + np.random.uniform(low=-0.4, high=0.4, size=len(df))\n",
    "\n",
    "df.plot.scatter(x='value', y='confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_sents = [{\n",
    "    \"text\": sent.getText(),\n",
    "    \"sentiment_polarity\": sent.sentiment['value'],\n",
    "    \"sentiment_confidence\": sent.sentiment['confidence'],\n",
    "    \"original_name\": sent.getMaskedInfo(\"[NAME]\")[0][0],\n",
    "    \"name_location\":sent.getMaskedInfo(\"[NAME]\")[0][1],\n",
    "    \"tagged_words\": [(word.txt, word.named_entity_tag) for word in sent.words],\n",
    "} for sent in masked_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(json_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../data/processed/masked_sents.json', 'w') as outfile:\n",
    "    json.dump(json_sents, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
