{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "src_path =   '../src' # change as needed\n",
    "sys.path.insert(0,src_path)\n",
    "\n",
    "import numpy as np\n",
    "import data_generator\n",
    "import model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 3089.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        tag  cat  occurences\n",
      "0    B-MISC    0           4\n",
      "1     I-LOC    1        2510\n",
      "2    I-MISC    2        1137\n",
      "3     I-ORG    3        1819\n",
      "4     I-PER    4        8244\n",
      "5         O    5       53099\n",
      "6  [nerCLS]    6        3000\n",
      "7  [nerPAD]    7      295291\n",
      "8  [nerSEP]    8        3000\n",
      "9    [nerX]    9       15896\n",
      "\n",
      "                tag  cat  occurences\n",
      "0  AFRICAN-AMERICAN    0        3405\n",
      "1          EUROPEAN    1        1538\n",
      "2         [raceCLS]    2        3000\n",
      "3         [racePAD]    3      295291\n",
      "4         [raceSEP]    4        3000\n",
      "5           [raceX]    5       77766\n",
      "\n",
      "           tag  cat  occurences\n",
      "0       FEMALE    0        2838\n",
      "1         MALE    1        2105\n",
      "2  [genderCLS]    2        3000\n",
      "3  [genderPAD]    3      295291\n",
      "4  [genderSEP]    4        3000\n",
      "5    [genderX]    5       77766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Start session\n",
    "max_length = 128\n",
    "\n",
    "train_data, val_data, test_data = data_generator.GetData(max_length, sample=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "def getDebiasedModel(max_input_length, train_layers):\n",
    "    \n",
    "    in_id = tf.keras.layers.Input(shape=(max_input_length,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_input_length,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_input_length,), name=\"segment_ids\")\n",
    "\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "\n",
    "    bert_sequence = model_utils.BertLayer(n_fine_tune_layers=train_layers)(bert_inputs)\n",
    "\n",
    "    dense = tf.keras.layers.Dense(256, activation='relu', name='pred_dense')(bert_sequence)\n",
    "\n",
    "    dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n",
    "\n",
    "    pred = tf.keras.layers.Dense(10, activation='softmax', name='ner')(dense)\n",
    "    \n",
    "    genderPred = tf.keras.layers.Dense(6, activation='softmax', name='gender')(pred)\n",
    "\n",
    "    racePred = tf.keras.layers.Dense(6, activation='softmax', name='race')(pred)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs={\n",
    "        \"ner\": pred,\n",
    "        \"race\": racePred,\n",
    "        \"gender\": genderPred\n",
    "    })\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer (BertLayer)          (None, None, 768)    108931396   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pred_dense (Dense)              (None, None, 256)    196864      bert_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 256)    0           pred_dense[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ner (Dense)                     (None, None, 10)     2570        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, None, 6)      66          ner[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "race (Dense)                    (None, None, 6)      66          ner[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 109,130,962\n",
      "Trainable params: 7,287,438\n",
      "Non-trainable params: 101,843,524\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "model = getDebiasedModel(max_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "protect_loss_weight = 0.1\n",
    "pred_learning_rate = 2**-16\n",
    "protect_learning_rate = 2**-16\n",
    "num_epochs = 8\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_data, epochs, batch_size, debias,\n",
    "        protect_loss_weight = 0.1, \n",
    "        pred_learning_rate =  2**-16, \n",
    "        protect_learning_rate = 2**-16):\n",
    "\n",
    "    num_train_samples = len(train_data[\"nerLabels\"])\n",
    "\n",
    "    ids_ph = tf.placeholder(tf.float32, shape=[batch_size, max_length])\n",
    "    masks_ph = tf.placeholder(tf.float32, shape=[batch_size, max_length])\n",
    "    sentenceIds_ph = tf.placeholder(tf.float32, shape=[batch_size, max_length])\n",
    "\n",
    "    gender_ph = tf.placeholder(tf.float32, shape=[batch_size, max_length])\n",
    "    ner_labels_ph = tf.placeholder(tf.float32, shape=[batch_size, max_length])\n",
    "\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 0.001\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 1000, 0.96, staircase=True)\n",
    "\n",
    "    protect_vars = [var for var in tf.trainable_variables() if 'gender' in var.name]\n",
    "    pred_vars = model.layers[3]._trainable_weights + [var for var in tf.trainable_variables() if any(x in var.name for x in [\"pred_dense\",\"ner\"])]\n",
    "\n",
    "    y_pred = model([ids_ph, masks_ph, sentenceIds_ph], training=True)\n",
    "\n",
    "    ner_loss = model_utils.custom_loss(ner_labels_ph, y_pred[\"ner\"])\n",
    "    gender_loss = model_utils.custom_loss_protected(gender_ph, y_pred[\"gender\"])\n",
    "\n",
    "    protect_opt = tf.train.AdamOptimizer(protect_learning_rate)\n",
    "    pred_opt = tf.train.AdamOptimizer(pred_learning_rate)\n",
    "\n",
    "    protect_grads = {var: grad for (grad, var) in protect_opt.compute_gradients(gender_loss,var_list=pred_vars)}\n",
    "    pred_grads = []\n",
    "\n",
    "    tf_normalize = lambda x: x / (tf.norm(x) + np.finfo(np.float32).tiny)\n",
    "\n",
    "    for (grad, var) in pred_opt.compute_gradients(ner_loss, var_list=pred_vars):\n",
    "        unit_protect = tf_normalize(protect_grads[var])\n",
    "        # the two lines below can be commented out to train without debiasing\n",
    "        if debias:\n",
    "            grad -= tf.reduce_sum(grad * unit_protect) * unit_protect\n",
    "            grad -= tf.math.scalar_mul(protect_loss_weight, protect_grads[var])\n",
    "        pred_grads.append((grad, var))\n",
    "\n",
    "    pred_min = pred_opt.apply_gradients(pred_grads, global_step=global_step)\n",
    "    protect_min = protect_opt.minimize(gender_loss, var_list=[protect_vars], global_step=global_step)\n",
    "\n",
    "    model_utils.initialize_vars(sess)\n",
    "\n",
    "    # Begin training\n",
    "    for epoch in range(epochs):\n",
    "            \n",
    "        shuffled_ids = np.random.choice(num_train_samples, num_train_samples)\n",
    "\n",
    "        for i in range(1, num_train_samples//32 + 1):\n",
    "            \n",
    "            batch_ids = shuffled_ids[batch_size*i: batch_size*(i+1)]\n",
    "\n",
    "            batch_feed_dict = {ids_ph: train_data[\"inputs\"][0][batch_ids], \n",
    "                               masks_ph: train_data[\"inputs\"][1][batch_ids],\n",
    "                               sentenceIds_ph: train_data[\"inputs\"][2][batch_ids],\n",
    "                               gender_ph: train_data[\"genderLabels\"][batch_ids],\n",
    "                               ner_labels_ph: train_data[\"nerLabels\"][batch_ids]}\n",
    "\n",
    "            _, _, pred_labels_loss_value, pred_protected_attributes_loss_vale = sess.run([\n",
    "                pred_min,\n",
    "                protect_min,\n",
    "                ner_loss,\n",
    "                gender_loss\n",
    "            ], feed_dict=batch_feed_dict)\n",
    "            \n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(\"epoch %d; iter: %d; batch classifier loss: %f; batch adversarial loss: %f\" % (epoch, i, pred_labels_loss_value,\n",
    "                                                                     pred_protected_attributes_loss_vale))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{}/{} - \".format(iteration, total) + metrics, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/8\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float32' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b1976b26c9f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-fe0d37862f7a>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(train_data, epochs, batch_size, debias, protect_loss_weight, pred_learning_rate, protect_learning_rate)\u001b[0m\n\u001b[1;32m     70\u001b[0m             ], feed_dict=batch_feed_dict)\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mprint_status_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nerLabels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels_loss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mprint_status_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nerLabels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nerLabels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels_loss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c9d996dd0dd7>\u001b[0m in \u001b[0;36mprint_status_bar\u001b[0;34m(iteration, total, loss, metrics)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_status_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" - \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"{}: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\r{}/{} - \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c9d996dd0dd7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_status_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" - \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"{}: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\r{}/{} - \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float32' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "fit(train_data, num_epochs, batch_size, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
